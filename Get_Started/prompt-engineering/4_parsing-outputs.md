# Parsing Outputs: From Text to Structured Data ğŸ§©

When your AI agent gives you a wall of text, itâ€™s not very usefulâ€”especially if you want to extract details or plug responses into your app. Thatâ€™s where smart output parsing comes in: getting the model to return JSON, YAML, or XML so your code can process it reliably.

---

## Why Structure Matters

Imagine your AI says:

> â€œThe user mentioned MegaWidget 3000 and felt frustrated after two days.â€

Great for humansâ€”but not for your parser. Instead, clean, structured output looks like:

```yaml
product_name: MegaWidget 3000  
sentiment: Negative  
summary: Broke after 2 days, user frustrated  
```
Structured data is consistent, easy to parse, and less brittle for automation ğŸ› ï¸.

---

**1. Use Model Features**

- Some LLMs support structured outputs natively:
- OpenAI function-calling / JSON Mode â€“ define a JSON schema and the model does the rest.
- Gemini â€“ specify a response schema in the API config and it outputs structured JSON.

**2. Promptâ€‘Based Formatting**

- This method works across all models:
- Clearly ask: â€œReturn only JSON with keys X, Y, Zâ€
- Provide an example snippet or schema
- Be explicit: â€œDo not add prose or quotes around numbersâ€
- Use ast.literal_eval()-friendly formatting
- Show a JSON or YAML example in the prompt to guide structure

**3. Practical Prompt Templates**
Example â€“ JSON output:
```json
Please answer ONLY in this JSON format:
{
  "name": string,
  "age": number,
  "languages": [string]
}
```
- User: â€œ[user input here]â€
- Example â€“ YAML output (more human-friendly):Output in YAML:

```yaml
name: string  
age: number  
languages:  
  - string
```
YAML is often cheaper, cleaner, and easier for models to follow.

---

### 4. Tooling + Parsers
**LangChain Parsers**
LangChain includes built-in parsers:

`JsonOutputParser` â€“ streams and validates JSON output

`PydanticOutputParser` â€“ maps output to Python models with validation

These combine prompt instructions with code-level parsing. For example:

```python
from langchain.output_parsers import JsonOutputParser
from pydantic import BaseModel

class Movie(BaseModel):
    title: str
    year: int

parser = JsonOutputParser(pydantic_object=Movie)
prompt = PromptTemplate(
    input_variables=["plot"],
    template="Tell me about this movie plot:\n{plot}\n{format_instructions}"
)
formatted_prompt = prompt.format(
    plot="A space adventure involving robots.",
    format_instructions=parser.get_format_instructions()
)
response = llm(formatted_prompt)
movie = parser.parse(response)
```
### Handling Parsing Errors
Even with clear prompts, models can mess up. Here are strategies:

- Retry prompts â€“ ask the model to fix its output
- Output-fixing â€“ send back malformed output and say â€œformat this properlyâ€
- Structural validation â€“ use JSON Schema or Pydantic to catch and reject invalid output

---
